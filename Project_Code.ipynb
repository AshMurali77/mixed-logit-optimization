{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AshMurali77/mixed-logit-optimization/blob/main/Project_Code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rrCaBhjqsWOe"
      },
      "source": [
        "###Imports and Data Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yCcF1JmZysuw"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import torch.nn.functional as F\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the random seed for reproducibility\n",
        "def set_seed(seed):\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)  # if you are using multi-GPU.\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "# Example of setting the seed\n",
        "set_seed(42)"
      ],
      "metadata": {
        "id": "odhHC3e9bEeD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8gE13XeV0BeA"
      },
      "outputs": [],
      "source": [
        "columns = [\"Transaction ID\", \"Choice\", \"Price\", \"Cost\", \"Distance\", \"Electric\", \"Gas\", \"Hybrid\", \"High Performance\"]\n",
        "\n",
        "df = pd.read_csv(\"Data(HW8).txt\", sep=\"\\t\", header=None, names=columns)\n",
        "\n",
        "df['Transaction ID'] = df['Transaction ID'].astype(int)\n",
        "df['Choice'] = df['Choice'].astype(int)\n",
        "df['Price'] = df['Price'].astype(int)\n",
        "df['Cost'] = df['Cost'].astype(float)\n",
        "df['Distance'] = df['Distance'].astype(float)\n",
        "df['Electric'] = df['Electric'].astype(int)\n",
        "df['Gas'] = df['Gas'].astype(int)\n",
        "df['Hybrid'] = df['Hybrid'].astype(int)\n",
        "df['High Performance'] = df['High Performance'].astype(int)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "columns_to_scale = ['Price', 'Cost', 'Distance']\n",
        "data_to_scale = df[columns_to_scale]\n",
        "scaled_data = scaler.fit_transform(data_to_scale)\n",
        "df[columns_to_scale] = scaled_data\n",
        "\n",
        "X = np.asarray(df[[\"Price\", \"Cost\", \"Distance\", \"Electric\", \"Gas\", \"Hybrid\", \"High Performance\"]]).reshape((1484, 3, 7))\n",
        "y = np.asarray(df[[\"Choice\"]]).reshape((1484, 3))\n",
        "\n",
        "# Train-test split\n",
        "X_all_train, X_test = np.split(X, [1000])\n",
        "y_all_train, y_test = np.split(y, [1000])\n",
        "\n",
        "# Train-val split\n",
        "X_train, X_val = np.split(X_all_train, [700])\n",
        "y_train, y_val = np.split(y_all_train, [700])\n",
        "\n",
        "# Conversion to tensors\n",
        "X_all_train = torch.tensor(X_all_train, dtype=torch.float32)\n",
        "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
        "X_val = torch.tensor(X_val, dtype=torch.float32)\n",
        "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
        "\n",
        "y_all_train = torch.tensor(y_all_train, dtype=torch.long)\n",
        "y_train = torch.tensor(y_train, dtype=torch.long)\n",
        "y_val = torch.tensor(y_val, dtype=torch.long)\n",
        "y_test = torch.tensor(y_test, dtype=torch.long)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D08CMGR_tjZd"
      },
      "source": [
        "###Model Setup"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MixedLogitModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_segments):\n",
        "        super(MixedLogitModel, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(hidden_size, num_segments)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Original shape: (batch_size, num_alternatives, input_size)\n",
        "        num_alternatives = x.shape[1]  # Need to capture this dynamically\n",
        "        x = x.view(-1, x.size(2))  # Flatten input to fit linear layers\n",
        "\n",
        "        # Apply layers\n",
        "        out = self.fc1(x)\n",
        "        out = self.relu(out)\n",
        "        out = self.fc2(out)\n",
        "\n",
        "        # Reshape back to (batch_size, num_alternatives, num_segments) for softmax\n",
        "        out = out.view(-1, num_alternatives, out.size(1))\n",
        "\n",
        "        # Apply softmax across alternatives for each segment\n",
        "        out = F.softmax(out, dim=1)\n",
        "\n",
        "        # Mean pooling across segments\n",
        "        out = torch.mean(out, dim=2)\n",
        "\n",
        "        return out\n"
      ],
      "metadata": {
        "id": "Bi8GEFX1ELcf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VpjdIVIcX4Uy",
        "outputId": "4fc860f0-0e70-4d47-9a4e-be7e78070d47"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MixedLogitModel(\n",
            "  (fc1): Linear(in_features=7, out_features=10, bias=True)\n",
            "  (relu): ReLU()\n",
            "  (fc2): Linear(in_features=10, out_features=3, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "model = MixedLogitModel(7, 10, 3)\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gsCQG9rYOvFL"
      },
      "source": [
        "##Question 1:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mA4L2eWaOoIt"
      },
      "source": [
        "###Create Optimizers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XqvfgzvFtMrI"
      },
      "outputs": [],
      "source": [
        "#hyperparmeter values\n",
        "lr = [0.1, 0.2, 0.3, 0.4]\n",
        "mom = [0.3, 0.5, 0.6, 0.9]\n",
        "\n",
        "hyperparameters = []\n",
        "\n",
        "for rate in lr:\n",
        "  hyperparameters.append((rate, None))\n",
        "  for value in mom:\n",
        "    hyperparameters.append((rate, value))\n",
        "\n",
        "optimizers = {}\n",
        "\n",
        "for parameters in hyperparameters:\n",
        "\n",
        "  lr = parameters[0]\n",
        "  mom = parameters[1]\n",
        "\n",
        "  if None in parameters:\n",
        "    name = \"Vanilla \" + \"(\" + str(lr) + \")\"\n",
        "    optimizers[name] = optim.SGD(model.parameters(), lr=lr)\n",
        "\n",
        "  else:\n",
        "    name = \"Momentum \" + str(parameters)\n",
        "    optimizers[name] = optim.SGD(model.parameters(), lr=lr, momentum=mom)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C8ab1WYmPAck"
      },
      "source": [
        "###Calculate Training and Validation Losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pVkfRhdcRIB1"
      },
      "outputs": [],
      "source": [
        "# Establish number of epochs\n",
        "\n",
        "num_epochs = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1xgv6xouLyHR"
      },
      "outputs": [],
      "source": [
        "train_loss = {}\n",
        "validation_loss = {}\n",
        "\n",
        "# converts one-hot encoded class labels to class indicies\n",
        "y_train_class = torch.argmax(y_train, dim=1)\n",
        "y_val_class = torch.argmax(y_val, dim=1)\n",
        "\n",
        "for optimizer_name, optimizer_params in optimizers.items():\n",
        "    optimizer = optimizer_params\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        outputs = model(X_train)\n",
        "        loss = criterion(outputs, y_train_class)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if epoch == (num_epochs - 1): # store epoch 100/100 in dictionary to find minimized training loss\n",
        "          train_loss[optimizer_name] = loss.item()\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        outputs = model(X_val)\n",
        "        loss = criterion(outputs, y_val_class)\n",
        "        if epoch == (num_epochs - 1):\n",
        "          validation_loss[optimizer_name] = loss.item()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print training losses\n",
        "\n",
        "for model_name, loss in train_loss.items():\n",
        "  print(f\"{model_name} has a training loss of {loss:.5f}\")"
      ],
      "metadata": {
        "id": "PGU8joi1ZTxM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0576760b-4400-40a2-ed3f-086f17bce12e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vanilla (0.1) has a training loss of 1.07073\n",
            "Momentum (0.1, 0.3) has a training loss of 1.02970\n",
            "Momentum (0.1, 0.5) has a training loss of 1.00920\n",
            "Momentum (0.1, 0.6) has a training loss of 0.99973\n",
            "Momentum (0.1, 0.9) has a training loss of 0.98577\n",
            "Vanilla (0.2) has a training loss of 0.98421\n",
            "Momentum (0.2, 0.3) has a training loss of 0.98240\n",
            "Momentum (0.2, 0.5) has a training loss of 0.98039\n",
            "Momentum (0.2, 0.6) has a training loss of 0.97872\n",
            "Momentum (0.2, 0.9) has a training loss of 0.97513\n",
            "Vanilla (0.3) has a training loss of 0.97471\n",
            "Momentum (0.3, 0.3) has a training loss of 0.97423\n",
            "Momentum (0.3, 0.5) has a training loss of 0.97363\n",
            "Momentum (0.3, 0.6) has a training loss of 0.97295\n",
            "Momentum (0.3, 0.9) has a training loss of 0.97079\n",
            "Vanilla (0.4) has a training loss of 0.97040\n",
            "Momentum (0.4, 0.3) has a training loss of 0.97004\n",
            "Momentum (0.4, 0.5) has a training loss of 0.96959\n",
            "Momentum (0.4, 0.6) has a training loss of 0.96912\n",
            "Momentum (0.4, 0.9) has a training loss of 0.96688\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Question 1a: Print validation losses\n",
        "\n",
        "for model_name, loss in validation_loss.items():\n",
        "  print(f\"{model_name} has a validation loss of {loss:.5f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R0GOQGXvaOa7",
        "outputId": "b225aee0-a4a7-4310-adc5-2e8c9b3bb72a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vanilla (0.1) has a validation loss of 1.07526\n",
            "Momentum (0.1, 0.3) has a validation loss of 1.03965\n",
            "Momentum (0.1, 0.5) has a validation loss of 1.01738\n",
            "Momentum (0.1, 0.6) has a validation loss of 1.00500\n",
            "Momentum (0.1, 0.9) has a validation loss of 0.99396\n",
            "Vanilla (0.2) has a validation loss of 0.99208\n",
            "Momentum (0.2, 0.3) has a validation loss of 0.99118\n",
            "Momentum (0.2, 0.5) has a validation loss of 0.98981\n",
            "Momentum (0.2, 0.6) has a validation loss of 0.98914\n",
            "Momentum (0.2, 0.9) has a validation loss of 0.98858\n",
            "Vanilla (0.3) has a validation loss of 0.98863\n",
            "Momentum (0.3, 0.3) has a validation loss of 0.98842\n",
            "Momentum (0.3, 0.5) has a validation loss of 0.98836\n",
            "Momentum (0.3, 0.6) has a validation loss of 0.98816\n",
            "Momentum (0.3, 0.9) has a validation loss of 0.98784\n",
            "Vanilla (0.4) has a validation loss of 0.98740\n",
            "Momentum (0.4, 0.3) has a validation loss of 0.98713\n",
            "Momentum (0.4, 0.5) has a validation loss of 0.98680\n",
            "Momentum (0.4, 0.6) has a validation loss of 0.98657\n",
            "Momentum (0.4, 0.9) has a validation loss of 0.98497\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IjVAOryhQjR5"
      },
      "source": [
        "###Best Vanilla + Momentum Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lFAxripJ2Hyt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0df47a69-f71f-4e4a-c321-5132849ebb0e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The parameters with the lowest validation loss for vanilla is Vanilla (0.4)\n",
            "The parameters with the lowest validation loss for momentum is Momentum (0.4, 0.9)\n"
          ]
        }
      ],
      "source": [
        "# Question 1b: Best vanilla + momentum models\n",
        "\n",
        "min_vanilla_key = min((k for k in validation_loss if 'Vanilla' in k), key=validation_loss.get)\n",
        "min_momentum_key = min((k for k in validation_loss if 'Momentum' in k), key=validation_loss.get)\n",
        "\n",
        "print(f'The parameters with the lowest validation loss for vanilla is {min_vanilla_key}')\n",
        "print(f'The parameters with the lowest validation loss for momentum is {min_momentum_key}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sNmfFXG4QJfv"
      },
      "outputs": [],
      "source": [
        "# Store best optimizers\n",
        "\n",
        "best_opt = {}\n",
        "\n",
        "best_opt[min_vanilla_key] = optimizers[min_vanilla_key]\n",
        "best_opt[min_momentum_key] = optimizers[min_momentum_key]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hStkQp49Q38L"
      },
      "source": [
        "###Calculate Training (entire training data set) and Testing Losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hfBWXhN_5fin"
      },
      "outputs": [],
      "source": [
        "all_train_loss = {}\n",
        "test_loss = {}\n",
        "test_accuracy = {}\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "y_all_train_class = torch.argmax(y_all_train, dim=1)\n",
        "y_test_class = torch.argmax(y_test, dim=1)\n",
        "\n",
        "for optimizer_name, optimizer_params in best_opt.items():\n",
        "    optimizer = optimizer_params\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "      model.train()\n",
        "      outputs = model(X_all_train)\n",
        "      loss = criterion(outputs, y_all_train_class)\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      if epoch == (num_epochs - 1):\n",
        "          all_train_loss[optimizer_name] = loss.item()\n",
        "\n",
        "      model.eval()\n",
        "      with torch.no_grad():\n",
        "        for epoch in range(num_epochs):\n",
        "          outputs = model(X_test)\n",
        "          loss = criterion(outputs, y_test_class)\n",
        "          if epoch == (num_epochs - 1):\n",
        "            test_loss[optimizer_name] = loss.item()\n",
        "\n",
        "          _, predicted = torch.max(outputs, 1)\n",
        "          correct = (predicted == y_test_class).sum().item()\n",
        "          total = y_test.size(0)\n",
        "          accuracy = correct / total\n",
        "          test_accuracy[optimizer_name] = accuracy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v9OjKsZPsTGl",
        "outputId": "92950853-f15c-4b85-f775-f610044401ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Vanilla (0.4)': 0.9655735492706299,\n",
              " 'Momentum (0.4, 0.9)': 0.9674547910690308}"
            ]
          },
          "metadata": {},
          "execution_count": 208
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_train_loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YLvnqgersU2R",
        "outputId": "6b4e21ba-3cbc-4106-d002-18097e5c94a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Vanilla (0.4)': 0.9684457182884216,\n",
              " 'Momentum (0.4, 0.9)': 0.9642199277877808}"
            ]
          },
          "metadata": {},
          "execution_count": 209
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Question 1d: not sure why these are the exact same - need to take a look at this\n",
        "\n",
        "print(\"Testing Accuracies:\")\n",
        "for optimizer_name, acc in test_accuracy.items():\n",
        "    print(f\"{optimizer_name}: {acc*100:.5f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qGGHHJKkeD-U",
        "outputId": "7f1b1d27-bddd-4f96-d40a-50b7c3950496"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing Accuracies:\n",
            "Vanilla (0.4): 58.67769%\n",
            "Momentum (0.4, 0.9): 57.64463%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###In-sample & out-of-sample gaps"
      ],
      "metadata": {
        "id": "9yd26jagbnYO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NucJazt0PwC3",
        "outputId": "31fd298c-4253-4eec-9f10-1231428105a6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Vanilla (0.4)': 0.002872169017791748,\n",
              " 'Momentum (0.4, 0.9)': 0.00323486328125}"
            ]
          },
          "metadata": {},
          "execution_count": 211
        }
      ],
      "source": [
        "# Calculate difference in all training vs testing\n",
        "\n",
        "train_test_diff = {key: abs(all_train_loss[key] - test_loss[key]) for key in set(all_train_loss) & set(test_loss)}\n",
        "\n",
        "train_test_diff"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model with smallest in vs out of sample gap\n",
        "\n",
        "best_improvement = min((k for k in train_test_diff), key=train_test_diff.get)\n",
        "\n",
        "print(best_improvement)"
      ],
      "metadata": {
        "id": "ZWE_2A4hWc_v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1967b740-3003-483e-fd66-14b431d56159"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vanilla (0.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZEdDGmtcR0qD"
      },
      "outputs": [],
      "source": [
        "# Document weights and biases\n",
        "\n",
        "for name, param in model.named_parameters():\n",
        "  if param.requires_grad:\n",
        "    print(name, param.data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tUUNVb2H9yVo"
      },
      "source": [
        "###Question Set #2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wv-RPmNfx9_D"
      },
      "outputs": [],
      "source": [
        "num_epochs = 100\n",
        "\n",
        "N_val = [1, 2, 10, 100, 1000]\n",
        "models = {}\n",
        "\n",
        "y_all_train_class = torch.argmax(y_all_train, dim=1)\n",
        "y_test_class = torch.argmax(y_test, dim=1)\n",
        "\n",
        "for N in N_val:\n",
        "  name = str(N) + \" Customer Segments\"\n",
        "  models[name] = MixedLogitModel(7, N, 3)\n",
        "\n",
        "all_train_loss_2 = {}\n",
        "test_loss_2 = {}\n",
        "test_accuracy_2 = {}\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "for name, model in models.items():\n",
        "\n",
        "  optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "  for epoch in range(num_epochs):\n",
        "      model.train()\n",
        "      outputs = model(X_all_train)\n",
        "      loss = criterion(outputs, y_all_train_class)\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      if epoch == (num_epochs - 1):\n",
        "        all_train_loss_2[name] = loss.item()\n",
        "\n",
        "      model.eval()\n",
        "      with torch.no_grad():\n",
        "        for epoch in range(num_epochs):\n",
        "          outputs = model(X_test)\n",
        "          loss = criterion(outputs, y_test_class)\n",
        "          if epoch == (num_epochs - 1):\n",
        "            test_loss_2[name] = loss.item()\n",
        "\n",
        "          _, predicted = torch.max(outputs, 1)\n",
        "          correct = (predicted == y_test_class).sum().item()\n",
        "          total = y_test.size(0)\n",
        "          accuracy = correct / total\n",
        "          test_accuracy_2[name] = accuracy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Testing Accuracies:\")\n",
        "for optimizer_name, acc in test_accuracy_2.items():\n",
        "    print(f\"{optimizer_name}: {acc*100:.5f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FhVASnxFfT3J",
        "outputId": "1a5ff08a-60ff-4c40-f4f6-32ac44bfd38b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing Accuracies:\n",
            "1 Customer Segments: 37.60331%\n",
            "2 Customer Segments: 49.17355%\n",
            "10 Customer Segments: 45.45455%\n",
            "100 Customer Segments: 56.40496%\n",
            "1000 Customer Segments: 56.61157%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for model_name, loss in all_train_loss_2.items():\n",
        "  print(f\"{model_name} has a training loss of {loss:.5f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fOxWszzvc7if",
        "outputId": "88087af6-12dc-4b6f-d899-463a787aed5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 Customer Segments has a training loss of 1.09739\n",
            "2 Customer Segments has a training loss of 1.07311\n",
            "10 Customer Segments has a training loss of 1.06790\n",
            "100 Customer Segments has a training loss of 1.00137\n",
            "1000 Customer Segments has a training loss of 0.97152\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bEFEP-1Czq1U",
        "outputId": "cf6253a7-d022-4da7-d309-9d7c98f6f185"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'1 Customer Segments': 0.00021195411682128906,\n",
              " '2 Customer Segments': -0.0006042718887329102,\n",
              " '10 Customer Segments': -0.0008310079574584961,\n",
              " '1000 Customer Segments': 0.00988858938217163,\n",
              " '100 Customer Segments': 0.013848483562469482}"
            ]
          },
          "metadata": {},
          "execution_count": 218
        }
      ],
      "source": [
        "train_test_diff2 = {key: all_train_loss_2[key] - test_loss_2[key] for key in set(all_train_loss_2) & set(test_loss_2)}\n",
        "\n",
        "train_test_diff2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_model = min((k for k in test_loss_2), key=test_loss_2.get)\n",
        "\n",
        "print(final_model)"
      ],
      "metadata": {
        "id": "BXE_t7zKVTfP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7414989-a9b4-488e-c097-34106203e769"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1000 Customer Segments\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "657KONyc5PiW"
      },
      "source": [
        "###Question Set #3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2wiyULITsi4q"
      },
      "source": [
        "####Creating DataLoaders for Each Batch Size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RoBIHRRW3-6M"
      },
      "outputs": [],
      "source": [
        "batch_sizes = [1, 10, 100, 1000]\n",
        "train_val_loaders = {b: DataLoader(TensorDataset(X_all_train, y_all_train), batch_size=b, shuffle=True) for b in batch_sizes}\n",
        "test_loaders = {b: DataLoader(TensorDataset(X_test, y_test), batch_size=b, shuffle=False) for b in batch_sizes}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xU2xjNTlsnGV"
      },
      "source": [
        "####Training Model for Each Batch Size(3a)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_size = 7  # Number of features\n",
        "output_size = 3  # Number of choices\n",
        "N = 100  # Number of neurons\n",
        "model_losses = {}\n",
        "model_params = {}\n",
        "\n",
        "for b in batch_sizes:\n",
        "    model = MixedLogitModel(input_size, N, output_size)\n",
        "    optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    losses = []\n",
        "    epoch_avg_losses = []\n",
        "\n",
        "    print(f\"Training with Batch Size: {b}\")\n",
        "    for epoch in range(100):  # Adjust the number of epochs as needed\n",
        "        epoch_loss = []\n",
        "        for data, target in train_val_loaders[b]:\n",
        "            target = target.float()\n",
        "            model.train()\n",
        "            optimizer.zero_grad()\n",
        "            output = model(data)\n",
        "            loss = criterion(output, target)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            epoch_loss.append(loss.item())\n",
        "        avg_loss = np.mean(epoch_loss)\n",
        "        losses.extend(epoch_loss)\n",
        "        epoch_avg_losses.append(avg_loss)\n",
        "        if epoch == (num_epochs-1):\n",
        "          final_loss = avg_loss\n",
        "          model_losses[b] = avg_loss\n",
        "          model_params[b] = {name: param.data for name, param in model.named_parameters()}\n",
        "          print(f\"Final Training Loss for Batch Size {b}: {avg_loss:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y6Tyo8i9dF0s",
        "outputId": "4c05b269-5285-4c62-b36d-ff8514da0a84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training with Batch Size: 1\n",
            "Final Training Loss for Batch Size 1: 0.9665\n",
            "Training with Batch Size: 10\n",
            "Final Training Loss for Batch Size 10: 0.9837\n",
            "Training with Batch Size: 100\n",
            "Final Training Loss for Batch Size 100: 1.0373\n",
            "Training with Batch Size: 1000\n",
            "Final Training Loss for Batch Size 1000: 1.0943\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eVOwXaEystv4"
      },
      "source": [
        "####Evaluate Model Generalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s1sZ-WgyszMo",
        "outputId": "63a4f9aa-d4d1-4d15-8925-86e289cafd8d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing Loss for Batch Size 1: 0.5685\n",
            "Testing Loss for Batch Size 10: 1.0405\n",
            "Testing Loss for Batch Size 100: 1.0527\n",
            "Testing Loss for Batch Size 1000: 1.0952\n"
          ]
        }
      ],
      "source": [
        "test_losses = {}\n",
        "for b in batch_sizes:\n",
        "    model = MixedLogitModel(input_size, N, output_size)\n",
        "    model.load_state_dict(model_params[b])  # Load trained parameters\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    test_loss = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loaders[b]:\n",
        "            target = target.float()\n",
        "            output = model(data)\n",
        "            loss = criterion(output, target)\n",
        "            test_loss.append(loss.item())\n",
        "        if epoch == (num_epochs-1):\n",
        "          test_losses[b] = loss.item()\n",
        "          print(f\"Testing Loss for Batch Size {b}: {loss.item():.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Determine best Batch Size(3b)"
      ],
      "metadata": {
        "id": "SBhxYkE_ukba"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_gap_by_batch = {}\n",
        "best_batch = None\n",
        "smallest_loss_gap = float('inf')\n",
        "\n",
        "for b in batch_sizes:\n",
        "    model = MixedLogitModel(input_size, N, output_size)\n",
        "    model.load_state_dict(model_params[b])  # Load trained parameters\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # Calculate In-Sample (Training) Loss\n",
        "    in_sample_loss = []\n",
        "    with torch.no_grad():\n",
        "        for data, target in train_val_loaders[b]:\n",
        "            target = target.float()\n",
        "            output = model(data)\n",
        "            loss = criterion(output, target)\n",
        "            in_sample_loss.append(loss.item())\n",
        "    avg_in_sample_loss = np.mean(in_sample_loss)\n",
        "\n",
        "    # Calculate Out-of-Sample (Testing) Loss\n",
        "    out_of_sample_loss = []\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loaders[b]:\n",
        "            target = target.float()\n",
        "            output = model(data)\n",
        "            loss = criterion(output, target)\n",
        "            out_of_sample_loss.append(loss.item())\n",
        "    avg_out_of_sample_loss = np.mean(out_of_sample_loss)\n",
        "\n",
        "    # Calculate and store the gap\n",
        "    loss_gap = abs(avg_in_sample_loss - avg_out_of_sample_loss)\n",
        "    loss_gap_by_batch[b] = loss_gap\n",
        "\n",
        "    print(f\"Batch Size: {b}, In-Sample Loss: {avg_in_sample_loss:.4f}, Out-of-Sample Loss: {avg_out_of_sample_loss:.4f}, Loss Gap: {loss_gap:.4f}\")\n",
        "\n",
        "    # Update the best batch size with the smallest loss gap\n",
        "    if loss_gap < smallest_loss_gap:\n",
        "        smallest_loss_gap = loss_gap\n",
        "        best_batch = b\n",
        "\n",
        "# Final output\n",
        "print(f\"Best Batch Size for smallest gap between in-sample and out-of-sample losses: {best_batch} with a Loss Gap of: {smallest_loss_gap:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fl0f-wrNukHV",
        "outputId": "a3ec0018-3321-4b09-a484-018a3ba7c5a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch Size: 1, In-Sample Loss: 0.9653, Out-of-Sample Loss: 0.9567, Loss Gap: 0.0086\n",
            "Batch Size: 10, In-Sample Loss: 0.9836, Out-of-Sample Loss: 0.9725, Loss Gap: 0.0110\n",
            "Batch Size: 100, In-Sample Loss: 1.0371, Out-of-Sample Loss: 1.0332, Loss Gap: 0.0040\n",
            "Batch Size: 1000, In-Sample Loss: 1.0942, Out-of-Sample Loss: 1.0952, Loss Gap: 0.0010\n",
            "Best Batch Size for smallest gap between in-sample and out-of-sample losses: 1000 with a Loss Gap of: 0.0010\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Testing Accuracy(3c)"
      ],
      "metadata": {
        "id": "p8vHXa326WJ6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_by_batch = {}\n",
        "\n",
        "for b in batch_sizes:\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    model = MixedLogitModel(input_size, N, output_size)\n",
        "    model.load_state_dict(model_params[b])\n",
        "    model.eval()  # Ensure the model is in evaluation mode\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loaders[b]:\n",
        "            if target.ndim > 1 and target.shape[1] > 1:\n",
        "                target = torch.argmax(target, dim=1)\n",
        "            outputs = model(data)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += data.size(0)  # Ensure total is incremented by the number of samples in the batch\n",
        "            correct += (predicted == target).sum().item()\n",
        "\n",
        "    if total > 0:  # Safeguard against division by zero\n",
        "        accuracy = 100 * correct / total\n",
        "        accuracy_by_batch[b] = accuracy\n",
        "        print(f'Accuracy of the model with batch size {b}: {accuracy:.2f}%')\n",
        "    else:\n",
        "        print(f\"No data was processed for batch size {b}. Unable to calculate accuracy.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3PWpqOtR5xK_",
        "outputId": "93973662-3002-44e8-8401-c6299c1168f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the model with batch size 1: 58.06%\n",
            "Accuracy of the model with batch size 10: 56.82%\n",
            "Accuracy of the model with batch size 100: 51.24%\n",
            "Accuracy of the model with batch size 1000: 41.74%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_accuracy_batch = max(accuracy_by_batch, key=accuracy_by_batch.get)\n",
        "print(f\"Best performing batch size: {best_accuracy_batch} with an accuracy of {accuracy_by_batch[best_accuracy_batch]:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FZpQQKXJ7mRA",
        "outputId": "ff2ed2f2-dd76-4984-a100-cbda473d90a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best performing batch size: 1 with an accuracy of 58.06%\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}